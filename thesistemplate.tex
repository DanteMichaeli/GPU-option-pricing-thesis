%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                %%
%% An example for writting your thesis using LaTeX                %%
%% Original version by Luis Costa,  changes by Perttu Puska       %%
%% Support for Swedish added 15092014                             %%
%%                                                                %%
%% This example consists of the files                             %%
%%         thesistemplate.tex (versio 2.01)                       %%
%%         opinnaytepohja.tex (versio 2.01) (for text in Finnish) %%
%%         aaltothesis.cls (versio 2.01)                          %%
%%         kuva1.eps                                              %%
%%         kuva2.eps                                              %%
%%         kuva1.pdf                                              %%
%%         kuva2.pdf                                              %%
%%                                                                %%
%%                                                                %%
%% Typeset either with                                            %%
%% latex:                                                         %%
%%             $ latex opinnaytepohja                             %%
%%             $ latex opinnaytepohja                             %%
%%                                                                %%
%%   Result is the file opinnayte.dvi, which                      %%
%%   is converted to ps format as follows:                        %%
%%                                                                %%
%%             $ dvips opinnaytepohja -o                          %%
%%                                                                %%
%%   and then to pdf as follows:                                  %%
%%                                                                %%
%%             $ ps2pdf opinnaytepohja.ps                         %%
%%                                                                %%
%% Or                                                             %%
%% pdflatex:                                                      %%
%%             $ pdflatex opinnaytepohja                          %%
%%             $ pdflatex opinnaytepohja                          %%
%%                                                                %%
%%   Result is the file opinnaytepohja.pdf                        %%
%%                                                                %%
%% Explanatory comments in this example begin with                %%
%% the characters %%, and changes that the user can make          %%
%% with the character %                                           %%
%%                                                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Uncomment one of these:
%% the 1st when using pdflatex, which directly typesets your document in
%% pdf (use jpg or pdf figures), or
%% the 2nd when producing a ps file (use eps figures, don't use ps figures!).
\documentclass[english,12pt,a4paper,pdftex,sci,utf8]{aaltothesis}
%\documentclass[english,12pt,a4paper,dvips]{aaltothesis}

%% To the \documentclass above
%% specify your school: arts, biz, chem, elec, eng, sci
%% specify the character encoding scheme used by your editor: utf8, latin1

%% Use one of these if you write in Finnish (see the Finnish template):
%%
%\documentclass[finnish,12pt,a4paper,pdftex,elec,utf8]{aaltothesis}
%\documentclass[finnish,12pt,a4paper,dvips]{aaltothesis}

\usepackage{graphicx}
\usepackage[inkscapelatex=false]{svg}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float} % For [H]
\usepackage[ruled]{algorithm2e}
\SetKwComment{Comment}{/* }{ */}




%% Use this if you write hard core mathematics, these are usually needed
\usepackage{amsfonts,amssymb,amsbsy, amsmath}


%% Use the macros in this package to change how the hyperref package below 
%% typesets its hypertext -- hyperlink colour, font, etc. See the package
%% documentation. It also defines the \url macro, so use the package when 
%% not using the hyperref package.
%%
%\usepackage{url}

%% Use this if you want to get links and nice output. Works well with pdflatex.
\usepackage[hidelinks]{hyperref}
\hypersetup{pdfpagemode=UseNone, pdfstartview=FitH,
  colorlinks=true,urlcolor=red,linkcolor=blue,citecolor=black,
  pdftitle={Default Title, Modify},pdfauthor={Your Name},
  pdfkeywords={Modify keywords}}
\usepackage[capitalise,noabbrev]{cleveref}


\usepackage{float}


%% All that is printed on paper starts here
\begin{document}

%% Change the school field to specify your school if the automatically 
%% set name is wrong
 \university{aalto University}
 \school{School of Science}

%% Only for B.Sc. thesis: Choose your degree programme. 
\degreeprogram{Computer Science}
%%


%% Valitse yksi näistä kolmesta
%%
%% Choose one of these:
\univdegree{BSc}
%\univdegree{MSc}
%\univdegree{Lic}

%% Your own name (should be self explanatory...)
\author{Daniel Michaeli}

%% Your thesis title comes here and again before a possible abstract in
%% Finnish or Swedish . If the title is very long and latex does an
%% unsatisfactory job of breaking the lines, you will have to force a
%% linebreak with the \\ control character. 
%% Do not hyphenate titles.
%% 

\thesistitle{A Review of GPU Acceleration Techniques in Option Pricing Models}
\place{Espoo}

%% For B.Sc. thesis use the date when you present your thesis. 
%% 
%% Kandidaatintyön päivämäärä on sen esityspäivämäärä! 
\date{16.2.2025}

%% B.Sc. or M.Sc. thesis supervisor 
%% Note the "\" after the comma. This forces the following space to be 
%% a normal interword space, not the space that starts a new sentence. 
%% This is done because the fullstop isn't the end of the sentence that
%% should be followed by a slightly longer space but is to be followed
%% by a regular space.
%%
\supervisor{M.Sc.\ Henrik Lievonen} %{Prof.\ Pirjo Professori}

%% B.Sc. or M.Sc. thesis advisors(s). You can give upto two advisors in
%% this template. Check with your supervisor how many official advisors
%% you can have.
%%
%\advisor{Prof.\ Pirjo Professori}
%\advisor{D.Sc.\ (Tech.) Olli Ohjaaja}
\advisor{M.Sc.\ Henrik Lievonen}

%% Aalto logo: syntax:
%% \uselogo{aaltoRed|aaltoBlue|aaltoYellow|aaltoGray|aaltoGrayScale}{?|!|''}
%%
%% Logo language is set to be the same as the document language.
%% Logon kieli on sama kuin dokumentin kieli
%%
\uselogo{aaltoBlack}{''}

%% Create the coverpage
%%
\makecoverpage


%% Note that when writting your master's thesis in English, place
%% the English abstract first followed by the possible Finnish abstract

%% English abstract.
%% All the information required in the abstract (your name, thesis title, etc.)
%% is used as specified above.
%% Specify keywords
%%
%% Kaikki tiivistelmässä tarvittava tieto (nimesi, työnnimi, jne.) käytetään
%% niin kuin se on yllä määritelty.
%% Avainsanat
%%
\keywords{moi, mojn, moin, morjens, moro}
%% Abstract text
\begin{abstractpage}[english]

English bla bla bla
\end{abstractpage}

%% Force a new page so that the possible English abstract starts on a new page
%%
%% Pakotetaan uusi sivu varmuuden vuoksi, jotta 
%% mahdollinen suomenkielinen ja englanninkielinen tiivistelmä
%% eivät tule vahingossakaan samalle sivulle
\newpage
%

%% Force new page so that the Swedish abstract starts from a new page
\newpage
%
%% Swedish abstract. Delete if you don't need it. 
%% 
\thesistitle{Genomströmning och latens i datorsystem: en anlays av avvägningseffekter och optimeringsstrategier}
\advisor{M.Sc.\ Henrik Lievonen} %
\degreeprogram{Datateknik}
\department{Högskolan för teknikvetenskaper}%
\professorship{?}  %
%% Abstract keywords
\keywords{Nyckelord p\aa{} svenska,\\ Moi, moin, moidå, mojjdå}
%% Abstract text
\begin{abstractpage}[swedish]
 svenska bla bla bla
\end{abstractpage}

\newpage


%% Table of contents. 

\thesistableofcontents




%% Tweaks the page numbering to meet the requirement of the thesis format:
%% Begin the pagenumbering in Arabian numerals (and leave the first page
%% of the text body empty, see \thispagestyle{empty} below).
%% Additionally, force the actual text to begin on a new page with the 
%% \clearpage command.
%% \clearpage is similar to \newpage, but it also flushes the floats (figures
%% and tables).
%% There is no need to change these
%%
\cleardoublepage
\storeinipagenumber
\pagenumbering{arabic}
\setcounter{page}{1}


%% Text body begins. Note that since the text body
%% is mostly in Finnish the majority of comments are
%% also in Finnish after this point. There is no point in explaining
%% Finnish-language specific thesis conventions in English. Someday 
%% this text will possibly be translated to English.
%%
\section{Introduction}

%% Ensimm\"ainen sivu tyhj\"aksi
%% 
%% Leave first page empty
\thispagestyle{empty}
Options are a type of financial contract between two parties that grants the right -- but not the obligation -- to buy or sell a specific amount of an asset at a predetermined price by a specific future date \cite{hull2016options}. Options are thus considered a financial derivative, as their value is derived from the price of an underlying asset. Advances in both financial mathematics \cite{merton1994influence} and affordable computing power \cite{nordhaus2007two} have contributed to a rapid growth in the derivatives market. These developments have improved pricing models and risk management tools, making derivatives more accessible and practical. Consequently, their use has increased significantly over the last half-century, not only among investors and traders, but also among non-financial corporations \cite{bartram2009international}. Options and other derivatives facilitate both leveraged speculation and sophisticated risk management, allowing market participants to achieve more control over exposure to various financial risks.

There are many option pricing models, each based on different assumptions and with their own advantages and disadvantages. Regardless of the model chosen, computation speed remains a critical factor. In high-frequency trading, where transient market inefficiencies \textbf{(do I have to explain this?)} are quickly exploited over millions of trades, milliseconds can determine whether a strategy is profitable or not. Additionally, faster computation produces more available data within a given time frame, which aids in risk management practices that often include simulation and analysis of complex portfolios over many different scenarios. This has led to a rising interest in adapting option pricing algorithms to leverage GPU parallel computing capabilities. \textbf{(do I need to define GPU here? CS thesis after all)}

This thesis forms a literature review of common option pricing algorithms' GPU acceleration potential and limitations. The aim is to assess how dependency structures in different algorithms affect their GPU parallelization potential, what approaches see the greatest performance improvements of a GPU implementation, analyze the scalability of these solutions, and identify related bottlenecks. I have chosen to analyze the Cox-Ross-Rubinstein (CRR) binomial option pricing model, and Monte Carlo (MC) simulation-based methods. The Black-Scholes analytical formula has been excluded as its GPU implementation is purely arithmetic evaluation with no algorithmic content. Methods requiring PDE numerical solutions would offer rich parallelization challenges but demand mathematical background beyond this thesis's scope.

The ~\cref{sec:theory} introduces formal definitions and fundamental option pricing theory. ~\cref{sec:gpu} presents a high-level overview of the GPU, how it differs architecturally from the CPU, and how it can be used for general-purpose computing. ~\cref{sec:gpu-crr},~\cref{sec:gpu-bsm}, and~\cref{sec:gpu-mc} review GPU implementations of each respective approach, considering the aforementioned factors. The results are summarized in ~\cref{sec:summary} and conclusions are drawn in ~\cref{sec:conclusions}.

For scope restriction purposes, the following choices have been made:
\begin{itemize}
\item Only European and American options are considered, with the exception of the Monte Carlo methods, which are particularly suitable for pricing exotic options with complex payoff structures. The term \emph{vanilla options} refers to both European and American options, whereas \emph{exotic options} denotes more complex contracts. Unless explicitly stated otherwise, all discussions and conclusions apply to options in general. When specific terms are used, the statements pertain strictly to those contract styles. Furthermore, it is assumed that the underlying asset does not pay a dividend.
    
\item The purpose of this paper is to draw general conclusions about the GPU acceleration potential for different option pricing approaches. The referenced research makes use of varying computing architectures and performance metrics. Other differences, like the number of active cores in the baseline CPU implementation, or the extent to which further optimizations have been implemented, also play a role. This makes direct quantitative comparisons difficult. To account for this limitation, the main comparisons of interest are the relative speedups of the GPU-accelerated implementations compared to their respective baseline solutions, and to a smaller extent relative performance comparisons between different GPU-accelerated implementations.
    
\item The models and implementations are studied purely from the perspective of computational efficiency. That is, no interest is taken in the analysis of accuracy, numerical stability, or any other unrelated aspect. The focus remains exclusively on execution time improvements and parallelization potential.

\end{itemize}


%% Opinn\"aytteess\"a jokainen osa alkaa uudelta sivulta, joten \clearpage
%%
%% In a thesis, every section starts a new page, hence \clearpage
\clearpage

\section{Option Pricing Fundamentals} \label{sec:theory}

In the following section, I present a sufficient theoretical foundation for understanding and pricing options. Firstly, general definitions are established along with vanilla option payoff structures \textbf{(if these are two separate subsections, can I use word along here?)}. This is followed by a section \textbf{(do I hyperlink it?)} on the key determinants that influence option prices. Next, the no-arbitrage principle and risk-neutral valuation framework are presented, explaining the theory that underpins all pricing models. The section concludes with a discussion on the inherent computational challenges of option pricing, further motivating the exploration of GPU acceleration techniques. \textbf{have not written yet this inherent computational challenges thing, perhaps not necessary?} \


\subsection{Definitions}\label{subsec:definitions}
The following terminology is from Chapter 1.5 in Hull's classic book ``Options, Futures, and Other Derivatives'' \cite{hull2016options}:

\paragraph{Call Option:}Contract that grants the holder the right (but not the obligation) to buy the underlying asset by a certain date for a certain price.

\paragraph{Put Option:}Contract that grants the holder the right (but not the obligation) to sell the underlying asset by a certain date for a certain price.

\paragraph{Strike Price:}The predetermined price at which the underlying asset can be bought (for a call option) or sold (for a put option) upon exercise.

\paragraph{Maturity (date):}The predetermined date on which the option expires, determining the latest point at which it can be exercised.
\bigskip

Note the ambiguous use of ``by'' in the definitions above, as the specific rules for when an option can be exercised depends on the style of option. A European option can only be exercised on the maturity date, whereas an American option can be exercised at any time up to maturity. For clarity, the underlying asset will hereinafter be simply referred to as the stock, and the current stock price referred to as the \emph{spot price}. There are always two parties to every option contract: the buyer, who takes the \emph{long} position, pays an upfront premium to the underwriter (seller) for the right to engage in a future trade. Conversely, the underwriter, who takes the \emph{short} position, incurs an obligation to engage in this trade, thus assuming risk. \textbf{(I don't know whether to use emph, bold, or parentheses here for terminology)}

\subsection{Vanilla Option Payoff Structures}\label{subsec:payoffs}

An option is a zero-sum game between the buyer and the underwriter, hence we have a pair of mirrored positions for every contract. These can be visualized by graphing the profit at the time of exercising as a function of the spot price. Alternatively, one can consider the slightly modified \emph{payoff} of the position, which excludes the premium paid or received to focus only on the fundamental mechanics of the option itself, regardless of what someone paid for it: $\text{profit} = \text{payoff} - \text{premium}$. Profit diagrams for each vanilla option position are presented below, along with practical examples for intuition. The options are based on one unit of stock. Transaction costs and taxes are ignored, and we assume liquid markets to the extent that instantaneous buying and selling of assets is possible.

For a call option, the investor is willing to pay a premium upfront in order to fix a purchase price for a later time. In other words, they expect the price of the stock to increase enough to offset this premium. ~\cref{fig:long_call_payoff} depicts this position. As long as the spot price is less than the strike price, $S_T < K$, the buyer is at a net loss equal to the premium $p$. The option is said to be \emph{out of the money (OTM)} and has no intrinsic value. When $S_T = K$ the option is considered to be \emph{at the money (ATM)}, after which, when $S_T > K$ it is \emph{in the money (ITM)} and has intrinsic value equal to the payoff \cite{hull2013fundamentals}. Still, the profit remains negative as long as $\text{payoff} < p$. Only  after offsetting the premium does the option truly become profitable for the buyer. Note that the ``moneyness'' terminology is always defined from the perspective of the long position. Assuming liquid markets, the buyer could then exercise the option to buy the stock for the strike price, only to immediately sell for the spot price to profit off the difference. In general, ITM options are exercised, as the intrinsic value helps to offset at least part of the loss from paying the premium.\cite{hull2016options} To demonstrate options' role in risk management, as opposed to pure speculation, consider a manufacturer heavily reliant on crude oil. If this manufacturer anticipates a significant increase in oil prices a year from now, they might choose to enter a long position in a call option on crude oil. Here, the focus shifts from profit towards hedging against price risk, functioning similarly to insurance. The manufacturer willingly pays a premium to establish a price ceiling on future oil prices, and agrees on a strike price in accordance with their risk management strategy.

\begin{center}
\begin{figure}[H]
\centering
    \begin{tikzpicture}[scale=1.5, >=stealth]

        % Shade area to the right of K (extending fully up to x-axis)
        \fill[gray!10] (2,-1.5) -- (6,-1.5) -- (6,4) -- (2,4) -- cycle;

         % Shade area to the left of K (extending fully up to x-axis)
        \fill[gray!20] (0,-1.5) -- (2,-1.5) -- (2,4) -- (0,4) -- cycle;


        % Define axes (extended x-axis)
        \draw[->] (0,0) -- (6,0) node[below,xshift=-25,yshift=-2pt, align=center] {$S_T$ (€)};
        \draw[->] (0,-1.5) -- (0,4) node[above] {\small Profit (€)};
        
        
        % Strike price line
        \draw[dashed] (2,0) -- (2,-0.8) node[above, yshift=35] {\large$K$};
        
        % Payoff function (thicker blue line)
        \draw[line width=1.5pt, blue] (0,-0.8) -- (2,-0.8) -- (6,4);
        
        % Marking zero level
        \node[left] at (0,0) {0};
        
        % Adding the premium annotation
        \draw (-0.07,-0.8) -- (0,-0.8); % Short tick line
        \node[left] at (-0.1,-0.8) {\small $-p$};

        % Add "ITM" label inside the fully shaded area
        \node[gray!60] at (3,1.5) {\small \textbf{ITM}};

        % Add "OTM" label inside the fully shaded area
        \node[gray!60] at (1,1.5) {\small \textbf{OTM}};

    \end{tikzpicture}
    \caption{Profit diagram for the long position in a call option. $K$ = strike price, $S_T$ = spot price, $p$ = premium. The buyer pays a premium to fix a maximum purchase price for the stock at a later point in time. At maturity, as long as $S_T < K$ there is no incentive to exercise the option, and the profit thus equals $-p$. The option is worthless, and is considered out of the money (OTM). When $S_T > K$, the option is in the money (ITM) and is assumed to be exercised as the buyer can now purchase the stock for $K$, immediately sell it for $S_T$, and offset some or all of the premium paid. However, the investment is only profitable once $S_T - K > p$.}
    \label{fig:long_call_payoff}
\end{figure}
\end{center}

The short call position exhibits an inverse profit profile compared to the long position: as long as the option remains OTM, the underwriter retains the full premium as profit, since the investor will not exercise the option. Once the option becomes ITM, the buyer will exercise it, forcing the underwriter to sell the stock at the strike price $K$ despite its higher market value $S_T$. The premium initially offsets this adverse price difference until the breakeven point where $S_T-K=p$, after which the position becomes a loss for the underwriter.~\cref{fig:short_call_payoff} illustrates this position. Continuing with the previous example, this position could be taken by a crude oil producer with conviction that prices will remain below or near the strike price at maturity. The risk borne by the underwriter commands the premium.

Ignoring the premium, the payoff from the long position in a call option is defined as
\begin{equation}
    \max(S_T-K,0)
\label{eq:long_call_payoff}
\end{equation}
as the investor will only exercise when ITM to either profit or offset losses. Consequently, the payoff from the short position is defined as $-\max(S_T-K,0) = \min(K-S_T,0)$ due to the zero-sum nature of the contract.\footnote{For American-style options with the right to early-exercise, the payoff is calculated using $S_\tau$ instead of $S_T$, where $\tau \le T$ is the chosen point of exercise.}\cite{hull2016options}

\begin{center}
\begin{figure}[H]
\centering
    \begin{tikzpicture}[scale=1.5, >=stealth]
        % Create a more balanced diagram by shifting the origin up
        % Define y-range from -3 to +2 instead of -4 to +4
        
        % Shade area to the right of K
        \fill[gray!10] (2,-3) -- (6,-3) -- (6,2) -- (2,2) -- cycle;
        % Shade area to the left of K
        \fill[gray!20] (0,-3) -- (2,-3) -- (2,2) -- (0,2) -- cycle;
        
        % Define axes with shifted x-axis (moved up)
        \draw[->] (0,0) -- (6,0) node[below,xshift=-25,yshift=-2pt, align=center] {$S_T$ (€)};
        \draw[->] (0,-3) -- (0,2) node[above] {\small Profit (€)};
        
        % Strike price line
        \draw[dashed] (2,0) -- (2,0.8) node[below, yshift=-35] {\large$K$};
        
        % Payoff function (thicker red line for short position)
        \draw[line width=1.5pt, red] (0,0.8) -- (2,0.8) -- (6,-3);
        
        % Marking zero level
        \node[left] at (0,0) {0};
        
        % Adding the premium annotation
        \draw (-0.07,0.8) -- (0,0.8); % Short tick line
        \node[left] at (-0.1,0.8) {\small $+p$};
        
        % Add labels inside the shaded areas
        \node[gray!60] at (1,-1.5) {\small \textbf{OTM}};
        \node[gray!60] at (3,-1.5) {\small \textbf{ITM}};
    \end{tikzpicture}
    \caption{Profit diagram for the short position in a call option. $K$ = strike price, $S_T$ = spot price, $p$ = premium. The underwriter receives a premium but is obligated to sell the stock for $K$ at a later time point, should the option be exercised. When $S_T < K$, the option is worthless and considered out of the money (OTM), allowing the underwriter to keep the full premium as profit. When $S_T > K$ and the option is exercised in the money (ITM), the underwriter is forced to sell the stock at the strike price $K$ despite its higher market value $S_T$. The profit decreases linearly as $S_T$ increases, becoming negative once $S_T - K > p$.}
    \label{fig:short_call_payoff}
\end{figure}
\end{center}

For a put option, the investor is willing to pay a premium up front to secure a minimum selling price for the stock at a later time point. They expect the price of the stock to decrease sufficiently to offset this premium. Conversely, the underwriter receives the premium but assumes the obligation to purchase the stock at the strike price $K$, should the option be exercised.~\cref{fig:put_option_payoffs} depicts the profit diagrams of the long and short positions of a put option. A put option is OTM when $S_T > K$ as the investor will not exercise it to sell the stock for a lower price than market value. By the same token, the option is ITM when  $S_T < K$, as the investor can then buy the stock asset at market value and sell it for the strike price \cite{hull2013fundamentals}. Again, being ITM is not sufficient to be profitable - the price difference must be large enough to offset the paid premium. An example use case would be a crude oil supplier forecasting low prices in a year's time and entering the long position to secure a minimum revenue. Again, a premium is paid to hedge against a risk of price swings. The short side would be taken by a market participant who anticipates crude oil prices not to fall enough to offset the received premium.

\begin{figure}[H]
\centering

\begin{subfigure}[t]{0.45\textwidth}
\centering
\resizebox{\linewidth}{!}{%
\begin{tikzpicture}[>=stealth]
    \fill[gray!20] (4,-1.5) -- (6,-1.5) -- (6,4) -- (4,4) -- cycle;
    \fill[gray!10] (0,-1.5) -- (4,-1.5) -- (4,4) -- (0,4) -- cycle;
    \draw[->] (0,0) -- (6,0) node[below,xshift=-25,yshift=-2pt] {$S_T$ (€)};
    \draw[->] (0,-1.5) -- (0,4) node[above] {Profit (€)};
    \draw[dashed] (4,0) -- (4,-0.8) node[above,yshift=25] {\large$K$};
    \draw[line width=1.5pt, blue] (0,4) -- (4,-0.8) -- (6,-0.8);
    \node[left] at (0,0) {0};
    \draw (-0.07,-0.8) -- (0,-0.8);
    \node[left] at (-0.1,-0.8) {\small $-p$};
    \node[gray!60] at (3,1.5) {\small \textbf{ITM}};
    \node[gray!60] at (5,1.5) {\small \textbf{OTM}};
\end{tikzpicture}%
}
\caption{Long put option payoff}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.45\textwidth}
\centering
\resizebox{\linewidth}{!}{%
\begin{tikzpicture}[>=stealth]
    \fill[gray!20] (4,-3) -- (6,-3) -- (6,2.5) -- (2,2.5) -- cycle;
    \fill[gray!10] (0,-3) -- (4,-3) -- (4,2.5) -- (0,2.5) -- cycle;
    \draw[->] (0,0) -- (6,0) node[below,xshift=-25,yshift=-2pt] {$S_T$ (€)};
    \draw[->] (0,-3) -- (0,2.5) node[above] {Profit (€)};
    \draw[dashed] (4,0) -- (4,0.8) node[below,yshift=-25] {\large$K$};
    \draw[line width=1.5pt, red] (0,-3) -- (4,0.8) -- (6,0.8);
    \node[left] at (0,0) {0};
    \draw (-0.07,0.8) -- (0,0.8);
    \node[left] at (-0.1,0.8) {\small $+p$};
    \node[gray!60] at (5,-1.5) {\small \textbf{OTM}};
    \node[gray!60] at (3,-1.5) {\small \textbf{ITM}};
\end{tikzpicture}%
}
\caption{Short put option payoff}
\end{subfigure}

\caption{Profit diagrams for long (a) and short (b) positions in a put option. $K$ = strike price, $S_T$ = spot price, $p$ = premium. For the long position, the buyer pays a premium to secure a minimum selling price for the stock at a future time point. When $S_T < K$ the option is in the money (ITM) and would be exercised, as the underwriter is forced to buy the stock for $K$ despite its lower market value $S_T$. When $S_T > K$ the option is out of the money (OTM) with no incentive to exercise, resulting in a loss $-p$. For the short position, the underwriter receives the premium but assumes the obligation to purchase the stock at $K$, should the option be exercised. The underwriter profits fully when the option remains OTM, but faces decreasing profits when ITM as the spot price decreases. The position becomes unprofitable once $K-S_T > p$.}
\label{fig:put_option_payoffs}
\end{figure}

The payoff from the long position in a put option is defined as
\begin{equation}
    \max(K-S_T,0)
\label{eq:long_put_payoff}
\end{equation}
as being ITM now means $K > S_T$. Conversely, the payoff in the corresponding short position is $-\max(K-S_T,0) = \min(S_T-K,0)$ \cite{hull2016options}.

The long position in any option contract is never obligated to exercise, and the loss is therefore limited to the premium paid. On the other hand, the underwriter is always obligated to engage in a disadvantageous trade with the buyer. Additionally, since underlying asset prices have no theoretical upper bound but are limited to non-negative values, the short call position faces potentially unlimited losses. \cref{tab:options_table} aggregates information about the extreme-case profit and loss incurred from the different option types and positions.

\begin{table}[!htb]
\centering
\caption{Extreme-case upside and downside potential for different option positions. $p$ = premium paid or received, $K$ = strike price. The long position in a call option has unlimited upside potential due to theoretically unbounded underlying asset prices, with losses limited to the premium paid. The corresponding short position mirrors this behavior with unlimited downside risk. Put options have bounded payoffs as asset prices cannot fall below zero. The maximum gain for a long put position is $K-p$ when the spot price reaches zero, and the maximum loss for the corresponding short position is $-(K-p)$.}\label{tab:options_table}
\begin{tabular}{|l|p{5cm}|p{5cm}|}
\hline
\textbf{} & \textbf{Call Option} & \textbf{Put Option} \\
\hline
\textbf{Long} & \textbf{Maximum Gain:} $+\infty$
\newline \textbf{Maximum Loss:} $-p$ & \textbf{Maximum Gain:} $K-p$
\newline \textbf{Maximum Loss:} $-p$ \\
\hline
\textbf{Short} & \textbf{Maximum Gain:} $+p$
\newline \textbf{Maximum Loss:} $-\infty$ & \textbf{Maximum Gain:} $+p$
\newline \textbf{Maximum Loss:} $-(K-p)$ \\
\hline
\end{tabular}
\end{table}

The objective of pricing models is to find the so-called fair value of the option~$p$. Although market prices form through the dynamic interaction of buyers and sellers, they are still largely anchored by theoretical pricing frameworks. These models provide a rational foundation for valuing derivatives based on mathematical and economic theory. While real-world prices may show short-term deviations, markets tend to converge toward theoretically justified values over time, as persistent mispricing creates exploitable opportunities. The theoretical fair value serves as a crucial reference point that informs trading decisions and risk management strategies.

\subsection{Price Determinants}

Hull et al. \cite{hull2013fundamentals} define six factors influencing the price of the option. While these factors typically serve as variables in pricing models, their effects can be intuitively understood even without formal mathematical frameworks. When analyzing a factor's impact, it is usually done in a ``ceteris paribus'' manner. In practice, however, this isolation rarely occurs, as markets quickly incorporate all available information into prices \cite{fama1970efficient}, causing interrelated changes among the factors themselves. For clarity, the following analysis considers the long position, though the same reasoning applies symmetrically to the short position, as both sides value the same option.

The stock price relative to the strike price is perhaps the most obvious factor. The effect on the payoff is thoroughly explained in \cref{subsec:payoffs}, and the price naturally increases with the payoff. Thus, the price of a call option increases with the stock price, while the inverse relationship is observed for a put option.

Volatility, a statistical measure of the variation in asset prices over a specific time period, has a positive effect on both call and put options. This positive relationship can be motivated by the limited downside -- unlimited upside nature of options (~\ref{fig:optiontable}). Higher stock price volatility increases the probability of significant movements, making it more likely the option will move ITM. The benefit is especially pronounced for OTM positions, where substantial price movement is needed to avoid expiring worthless, but holds for ITM positions as well. In the latter case, the unlimited potential for becoming even deeper ITM outweighs the limited downside risk of moving OTM.

Time to maturity has a more complex relationship with the price, and depends on both the option style and the context. For American options with possibility of early exercise, it makes sense that an expiration date further in the future leads to more opportunity for favorable movements in the stock price, thereby commanding a higher price. This time value argument is similar to that made for volatility, where the asymmetric payoff structure means additional potential for gain typically outweighs the risk of further losses. While this time value argument also holds for European options, the lack of early-exercise ability introduces complications. Hull et al. \cite{hull2013fundamentals} identify specific scenarios where American options derive significant additional value from the early exercise privilege. One example is when a future dividend payment to shareholders is expected, which theoretically decreases the share price and thereby the value of the corresponding call option. Similarly, a put option might be more valuable with a shorter time to maturity in the case of a very deep ITM position, such as when the underlying company has filed for bankruptcy. The option will almost certainly expire ITM, and thus by the \emph{time value of money} \textbf{(should I explain this in a footnote in greater detail?)} principle this cash flow is worth more the earlier it is received \cite{berk2007corporate}.

The risk-free rate represents the return on investment one can expect from a so-called risk-free investment, typically government-backed treasury securities. It serves as a benchmark against which investors compare expected returns of riskier investments. An increase in the risk-free rate typically leads to investors demanding higher returns across all risk levels. In option pricing, the risk-free rate primarily affects the time value component through the discounting of future cash flows. For a call option, a higher risk-free rate reduces the present value of the strike price that will be paid in the future\footnote{The present value of a future cash flow is calculated by discounting it using an appropriate rate. This rate reflects both the time value of money and opportunity cost. The risk-free rate represents the minimum discount rate, as it corresponds to the return available from risk-free investments. For risky cash flows, an additional risk premium is added to this base rate.}. This economic advantage for the buyer is reflected in the market through a higher option price. Conversely, for put options, a higher risk-free rate decreases the present value of the strike price to be received in the future, reducing the economic benefit to the holder and thereby decreasing the option's price. In practice, however, interest rates impact stock prices as well, making this relationship more complex when applied to actual markets.

The final determinant considers the dividend policy of the underlying company. Theoretically, a company's share price is reduced by the dividend amount on the ex-dividend date, as this cash is directly distributed from the company's assets to shareholders \cite{modigliani1958cost}. For call options, expected dividends decrease value because they reduce the expected future price of the stock without providing any benefit to the option buyer. Conversely, put options increase in value with higher expected dividends, as they decrease the value of the stock. This dividend effect is particularly significant for longer-dated options, where multiple dividend payments may occur before expiration, and for options near the money, where the dividend-induced price movement can meaningfully change the moneyness of the option.

\subsection{No-Arbitrage Pricing and Risk-Neutral Valuation}\label{sec:risk-neutral-theory}
Previously, all main "ingredients" for the pricing formulas were introduced. This section outlines the foundational theoretical framework that underpins all option pricing models, bringing us one step closer to formulating the models to be GPU-accelerated. In line with the thesis scope, the focus will be on intuition rather than mathematical rigor. Avid readers are encouraged to explore the references in greater detail \cite{hull2016options, gisiger2010risk, tham2001risk}. The assumptions presented in \cref{subsec:payoffs} continue to hold, as will the referral of the underlying asset as the stock. The setup considers European-style options, but in this single-period setting, the results are equally valid for American options, as early exercise provides no advantage.

A natural starting point is to consider how other financial assets are valued. The theoretical value of an asset is commonly understood as the discounted sum of all future cash flows it produces. Under uncertainty -- as is the case of all risky assets -- a standard approach would be to discount the \emph{expected value} of these cash flows, which represents a theoretical long-term average of the returns \textbf{(basic math and financial theory, do I need src for this?)}. Calculating this expected value, however, requires defining a set of possible outcomes and assigning probabilities to each. This is a fundamental limitation of pricing models, as the estimates are often questionable and, at least in part, subjective. Nonetheless, starting out with a simplistic model will lead to interesting and useful revelations that can be expanded on.

The \emph{no-arbitrage principle} is the essential assumption for what is to come. Arbitrage describes the act of simultaneous buying and selling of the same asset in different markets to make risk-free profit off price differences. Imagine the price of tomatoes being higher in one of two neighboring towns. Perhaps the tomato farmers were really successful in town A this year, and the increased supply dropped the prices somewhat. This information has not yet been priced into the tomatoes in town B. The astute tradesman could then buy tomatoes in town A and immediately sell them in town B to pocket the difference, without taking any position on future tomato price movements. This, again, assumes ideal conditions, like enough liquidity to always be able to both buy and sell, as well as ignoring friction costs like transportation. The idea behind our assumption is that this strategy ultimately is self-eliminating: as the tradesman continues to introduce more tomatoes to the total supply in town B they will drive the price down until an equilibrium has been reached. Other people may take notice and decide to adopt the same strategy, eliminating the opportunity even faster. The information about the larger supply in town A has now been priced into the tomatoes in town B. This example is not too far-fetched from reality. Modern digital markets do not perfectly adhere to the assumptions laid out above, and short-term arbitrage opportunities can exist. Nevertheless, as sophisticated market participants exploit these inefficiencies they quickly disappear due to subsequent price corrections. Thus, the no-arbitrage principle is a reasonable assumption, at least over longer time periods. If our pricing methodology is based on summing future cash flows, it logically follows that in absence of arbitrage opportunities two assets producing the same cash flows must be priced equally \cite{hull2016options,wilmott2013paul}.

If it is possible to find an existing asset with identical future cash flows to those of the option, and whose price is already known, then by the no-arbitrage principle, the price of that asset should theoretically equal the price of the option. Hull et al. \cite{hull2013fundamentals} consider a one-step model as the simplest framework to apply this idea. In this discrete-time model, we consider the stock price evolution over a single period. Let $S_0$ denote the current stock price, and let $f$ be the current price of an option on one share, with time $T$ to maturity. The stock price is assumed to move to one of two possible future values: $S_0u$ or $S_0d$ ($u>1$, $d<1$). These correspond to the option payoffs $f_u$ and $f_d$, respectively. \cref{fig:oneperiodbinom} visualizes the model setup. This restriction makes it possible to construct a so-called \emph{replicating portfolio} that perfectly matches the option's payoff in both states. This portfolio consists of $\Delta$ shares of the stock, as well as $B$ amount of a risk-free asset (e.g., a savings account) growing at the risk-free rate $r$. After time $T$, the portfolio will take on one of two values, depending on whether the stock price increased or decreased. By equating the value of the portfolio in each case with the corresponding option payoff, one obtains a system of two equations and two unknowns, $\Delta$ and $B$.

\begin{equation*}
\begin{cases}
    \Delta (S_0u) + B(1+r) = f_u\\
    \Delta (S_0d) + B(1+r) = f_d
\end{cases}
\end{equation*}
Solving for these variables yields
\begin{equation*}
\begin{cases}
    \Delta = \frac{f_u - f_d}{S_0(u-d)}\\
    B = \frac{f_du-f_ud}{(u-d)(1+r)}
\end{cases}
\end{equation*}

It is evidently possible to construct a portfolio with identical payoff structure as the option itself, according to

\begin{equation}
     \frac{f_u - f_d}{S_0(u-d)} S_0 + \frac{f_du-f_ud}{(u-d)(1+r)}
\label{eq:replicating-portfolio}
\end{equation}

Under the no-arbitrage principle, the price of the option must thus equal the price of constructing the replicating portfolio, i.e., buying $\Delta$ shares and investing $B$ in a risk-free asset. Otherwise, one could buy the cheaper alternative while selling the more expensive to obtain a risk-free profit. A negative $\Delta$ implies shorting the underlying asset, and a negative $B$ implies borrowing money at the risk-free rate instead of lending (saving) it.
\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        scale=1.5,
        >=stealth,
        every node/.style={font=\normalsize}
    ]
    
    % Stock price nodes
    \node (S0) at (0,0) {$S_0$};
    \node (Su) at (4,2) {$S_0u$};
    \node (Sd) at (4,-2) {$S_0d$};
    
    % Add option payoffs directly under stock prices
    \node at (0,-0.5) {$f$};
    \node at (4,1.5) {$f_u$};
    \node at (4,-2.5) {$f_d$};
    
    % Edges without probabilities
    \draw[->, thick] (S0) -- (Su);
    \draw[->, thick] (S0) -- (Sd);
    
    % Timeline moved closer to the lattice
    \draw[->, thick] (0,-3) -- (4,-3);
    \node at (0,-3) [below] {$t=0$};
    \node at (4,-3) [below] {$t=T$};
    
    \end{tikzpicture}
    \caption{One-period binomial model showing stock price evolution and corresponding option payoffs. The stock price moves from $S_0$ to either $S_0u$ or $S_0d$, with corresponding option values $f_u$ and $f_d$. The replicating portfolio approach determines the option price $f$ without requiring knowledge of the actual probabilities of up or down movements.}
    \label{fig:oneperiodbinom}
\end{figure}

The derivation assumed neither a call nor a put option, and works therefore as a pricing model for any European option. A more interesting observation, however, is the fact that this pricing approach contains no information about the expected return of the stock, or the probability with which it will increase or decrease in value. The authors motivate this intuitively by the fact that such expectations are already reflected in the stock price itself, and need not be explicitly accounted for when pricing the derivative. The option is priced relative to the underlying stock.

This also leads to the fundamental concept of \emph{risk-neutral} valuation. \cref{eq:replicating-portfolio} can be rewritten as

\begin{equation*}
     \frac{1}{1+r}\left(f_u\frac{(1+r)-d}{u-d}+f_d\frac{u-(1+r)}{u-d}\right),
\end{equation*}

where the weights $\tilde{p} := \frac{(1+r)-d}{u-d}$ and $\tilde{q} := \frac{u-(1+r)}{u-d}$ sum to one and lie between 0 and 1 under the no-arbitrage condition $d \leq 1+r \leq u$. These are called risk-neutral probabilities, and the option price can thus be calculated as the expected value of its payoff using the risk-neutral probabilities, discounted at the risk-free rate

\begin{equation}
     \frac{1}{1+r}(f_u\cdot \tilde p + f_d \cdot (1-\tilde p)).
\label{eq:risk-neutral-expectancy}
\end{equation}

While there exist many misconceptions about risk-neutral valuation, it can simply be thought of as an algebraic reformulation of the problem into a more familiar version of discounting expected future cash flows. The risk-neutral probabilities are not predictions of any real-life events. They are mathematical weights that look and behave like probabilities, and produce the same price as the replicating portfolio while maintaining the no-arbitrage assumption. The term risk-neutral probability stems from the fact that the reformulation discounts by the risk-free rate, resembling how a risk-neutral investor would discount cash flows. This elegant reformulation enables the use of more tools from probability theory, and elements of it will be found in all of the models to be introduced later. The full derivation of this reformulation is provided in \cref{appendix:risk_neutral_derivation}. \cite{gisiger2010risk} \cite{tham2001risk}


\section{The GPU and Parallel Computing} \label{sec:gpu}
The graphics processing unit (GPU) is a processor specified for graphics-related processing. Starting in the 1980s, the demand for 2D and 3D graphically based consumer software, mainly driven by video games, surged. In practice, this entailed performing a large amount of floating-point operations per seconds (FLOPS) associated with graphical operations like shading and rasterization. Front-runners of delivering affordable graphics computing capabilities included NVIDIA and ATI Technologies (later acquired by Advanced Micro Devices (AMD)).\cite{sanders2010cuda} \cite{kirk2016programming}

Hennessy and Patterson \cite{hennessy2011computer} loosely define \emph{latency} as the time between the start and completion of a single event, and \emph{throughput} as the total amount of work performed in a given time. These metrics (and specific variants thereof) are widely used in computing performance contexts. While both central processing units (CPUs) and GPUs have seen performance improvements on both ends, the authors show that relative throughput improvements tend to outweigh relative latency improvements. This is not unreasonable - increasing throughput is (within limits) mostly a manner of providing more of the same resources already available. Latency improvements have, on the other hand, already reached closer to the theoretical limits imposed by the laws of physics \cite{hennessy2011computer} \cite{sanders2010cuda}. Suomela's summary of statistics on trends for both clock speed and instruction latencies corroborate these claims (cite PPC website?).

This, in combination with the fact that graphics-related calculations are well-structured for concurrency exploitation (covered in \cref{subsec:parallell}), led to the evolution towards the exceptionally throughput-optimized GPU architectures of today's age. At the same time, there grew an increasing interest in the utilization of these parallel computing capabilities for other purposes. However, these advances alone were insufficient in unlocking the potential for so-called general-purpose GPU (GPGPU) programming, as the hardware lacked the flexibility needed for general-purpose computing, and no GPGPU programming models and tools were readily available. The initial graphics-intended hardware and software ecosystems effectively forced developers to mask their problems as those found in the graphics domain. Only after advances in these areas could GPGPU programming truly flourish. In 2007, NVIDIA released the compute unified device architecture \emph{CUDA} and corresponding software tools that greatly removed earlier restrictions in favor of GPGPU-programming. The hardware was now directly accessible without considering graphics-related interfaces, and the software tool for writing CUDA applications was a simple extension layer on top of familiar C/C++. Today, GPGPU applications are found in a wide variety of fields, including computational finance. \cite{sanders2010cuda} \cite{kirk2016programming}

\subsection{CPU and GPU Architecture}

 \cref{fig:CPUandGPU} represents a very simple model of a modern CPU and GPU. The \emph{arithmetic logic unit} (ALU) is responsible for performing bitwise operations on data, \emph{registers} (not explicitly visible in figure) for storing memory addresses, instructions, and data to operate on, as well as additional supporting components, e.g. for control of flow, or communication with the external environment. The CPU operates in a loop of two-staged fetch-execute instruction cycles, where an instruction is first loaded into the so-called instruction register. After this, the instruction is decoded and executed, which in practice means either data processing, data transfer, or control logic related to the instruction sequence. This loop continues until the program halts due to either finishing or due to an interruption by another module.\cite{stallings2011operating}

CPUs have with time adapted to improve performance by utilizing various parallelism mechanisms. Instruction-level parallelism (ILP) refers to a set of techniques the processor uses for executing multiple instructions, either in part or fully, simultaneously. Common examples of these are pipelining, branch prediction and speculative execution. Processor architectures often contain \emph{single instruction multiple data} (SIMD) capabilities through large vector registers capable of storing multiples of the same data type, and instructions that can operate on these at once. And to top it off, most modern processors are multi-core, meaning they literally contain multiple instances of the main aforementioned components for use. This enables a higher thread-level parallelism (TLP), where a \emph{thread} — informally defined as an independent sequence of instructions that can be scheduled and executed as a separate unit of work \textbf{do I need src??} — can run on each core simultaneously. Despite this, the CPU remains primarily latency-optimized, and does not hold a candle to the typical GPU throughput. \cite{hennessy2011computer}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{CPUAndGPU.png}
    \caption{Simple diagrams of modern multi-core CPU and GPU architectures, showcasing their main respective components. Each CPU core contains an arithmetic logic unit (ALU) for performing bitwise operations and a control unit for handling program flow. Hierarchical (L1-L3) on-chip cache memory minimizes data transfer bottlenecks between the (D)RAM and the cores. On the GPU, streaming multiprocessors correspond to cores. The design clearly emphasizes parallel computing power over control and latency optimization. The PCI-Express serves as a data transfer interface between the processors. source: https://enccs.github.io/gpu-programming/2-gpu-ecosystem/ OK TO DO THIS??}
    \label{fig:CPUandGPU}
\end{figure}

In contrast, while lacking many of the sophistication that makes the CPU excel at sequential and "control-complex" tasks, the GPU fits in more raw computation power for a massively throughput-optimized architecture that excels at the specialized task of parallel numerical computation. The term single instruction multiple thread (SIMT) is often used to describe GPU computation, as the concurrency is enabled on thread-level by a massive amount of threads running scalar computations in parallel, as opposed to single-threaded computation using SIMD and ILP methods (or multi-threaded on a comparatively few cores). Suomela (cite PPC) has nicely summarized these differing parallelism paradigms. A modern CUDA-based GPU containing many independent \emph{streaming multiprocessors} (SM), which can be considered as a group of many \emph{streaming processors} (SP) (read: ALUs) sharing some control units and instruction memory registers. Threads are grouped in to groups of 32, called \emph{warps}, which always execute in lock-step, i.e. simultaneous execution on their respective data. The threads in a warp are thus dispatched to a corresponding amount of SPs using these shared resources. Similarly to a multi-core CPU, all SMs share a higher-latency global memory (akin to RAM), and are individually allocated a small but fast on-chip cache for minimizing data transfer bottlenecks, among other things (to be discussed later). \cite{sanders2010cuda} \cite{kirk2016programming} (cite PPC)



\subsection{Parallel Computing Fundamentals and GPU suitability}\label{subsec:parallell}

Types of parallelism (data, task, instruction)
Amdahl's Law and theoretical speedup limits
Dependency chains and their impact
Synchronization requirements
Characteristics of "GPU-friendly" algorithms
Identifying parallelizable components
MAKE POINT THAT GRAPHICS CALCULATIONS ON PIXESL ETC WERE LARGELY PARALLELIZABLE DUE TO LOW DEPENDENCY CHAINS  
Common computation patterns in finance
Performance metrics and evaluation






\subsection{(GP)GPU Programming Model}



add * footnote explaining warps vs blocks, link to Suomela PPC
Thread hierarchy (threads, blocks, grids)
Memory spaces (global, shared, constant, texture)

-> WHY THIS? difference between logical view vs hardware view. Logical for structuring problem (indexing) according to its "natural dimensions" better, and hardware independence no matter how many SMs available et.c. + shared memory constructs for synching work!




Hardware-Level Concerns (Managed by GPU)

Warp formation and execution (32 threads in lockstep)
Warp scheduling on available SMs
Thread masking during branch divergence
Memory coalescing at warp level
Register allocation per thread
L1/L2 cache management
SM resource allocation
Load balancing across SMs

Programmer-Level Concerns (Your Focus)

Block and grid dimensions that match problem structure
Thread indexing within problem domain
Shared memory allocation and usage
Managing data transfers between CPU and GPU
Minimizing thread divergence
Optimizing memory access patterns
Balancing resources per thread/block
Maximizing occupancy (concurrent warps)
Synchronization between threads when needed
Decomposing problem into parallel components

The key insight is that programmers think in terms of the problem structure (blocks/grids), while the hardware manages the execution details (warps/SMs). This separation of concerns is what makes CUDA both powerful and accessible.RetryClaude can make mistakes. Please double-check responses.





Execution model and scheduling
CUDA programming paradigm

\subsection{WHY GPU?} the need for computational power:

This is a crucial question that gets to the heart of why GPU acceleration is valuable in option pricing. The justification comes from several real-world financial applications:

Risk Management: Financial institutions need to calculate Value-at-Risk (VaR) and other risk metrics for portfolios containing thousands of options. This often requires:

Recalculating all option prices under multiple scenarios
Computing Greeks to understand sensitivity to market movements
Running these calculations daily or even intraday


Regulatory Requirements: Banking regulations like Basel III require comprehensive stress testing of portfolios, involving:

Calculating option values under hundreds of different market scenarios
Reporting results within strict timeframes


Electronic Market Making: Firms that provide liquidity in options markets need to:

Continuously update prices for hundreds or thousands of options
Adjust their quotes as market conditions change
Maintain accurate hedging calculations (based on Greeks)


Portfolio Optimization: Investment firms need to:

Evaluate complex trading strategies across multiple options
Test different portfolio compositions
Optimize hedging positions using sensitivity metrics



This computational demand is documented in various sources:

Academic papers like "GPU Computing in Finance: Recent Applications and Developments" by Giles \& Xiaosong (2014) discuss these requirements
Financial industry whitepapers from firms like NVIDIA and JP Morgan
Case studies from banks that have implemented GPU solutions for options pricing

The computational demands become especially intense during market stress when quick recalculation is critical, making the case for GPU acceleration even stronger.



- why GPU, why optimize for throughput vs latency


\clearpage

\section{GPU Acceleration of the Cox-Ross-Rubinstein Binomial Model} \label{sec:gpu-crr}

\subsection{The Cox-Ross-Rubinstein Model}

The Cox-Ross-Rubinstein (CRR) model extends the single-period framework into a multi-period setting, providing a more realistic model of asset price evolution over time. The model maintains the same assumptions as the single-period case: discrete time periods and constant multiplicative factors $u$ and $d$ for price movements. Over multiple periods, this creates a binomial lattice of possible price paths. This lattice expands outward from the initial stock price, generating multiple possible final states for both the stock and the corresponding option payoff. The CRR model solves for the initial option price using backward induction. Starting at the terminal nodes, where option payoffs are calculated using \cref{eq:long_call_payoff,eq:long_put_payoff}, the algorithm moves backward through the lattice. Each interior node is treated as a one-period binomial problem, and the option value is calculated using \cref{eq:risk-neutral-expectancy}. \cref{fig:crr-twoperiod} visualizes a two-period lattice, but this can be extended to an arbitrary number of periods. \cite{cox1979option}

\begin{figure}[tbp]
    \centering
    \begin{tikzpicture}[
        scale=1.3,
        >=stealth,
        every node/.style={font=\normalsize}
    ]
    
    % T = 0
    \node (S0) at (0,0) {$S_0$};
    \node at (0,-0.5) {$f$};
    \node at (0,-1.0) {\small $(C_{0,0})$};  % Moved down
    
    % T = 1
    \node (Su) at (3,1.5) {$S_0u$};
    \node at (3,1) {$f_u$};
    \node at (3,0.5) {\small $(C_{1,1})$};   % Moved down
    \node (Sd) at (3,-1.5) {$S_0d$};
    \node at (3,-2) {$f_d$};
    \node at (3,-2.5) {\small $(C_{1,0})$};  % Moved down
    
    % T = 2
    \node (Suu) at (6,2.5) {$S_0u^2$};
    \node at (6,2) {$f_{uu}$};
    \node at (6,1.5) {\small $(C_{2,2})$};   % Moved down
    \node (Sud) at (6,0) {$S_0ud$};
    \node at (6,-0.5) {$f_{ud}$};
    \node at (6,-1.0) {\small $(C_{2,1})$};  % Moved down
    \node (Sdd) at (6,-2.5) {$S_0d^2$};
    \node at (6,-3) {$f_{dd}$};
    \node at (6,-3.5) {\small $(C_{2,0})$};  % Moved down
    
    % Forward edges (stock price evolution)
    \draw[->, thick] (S0) -- (Su);
    \draw[->, thick] (S0) -- (Sd);
    \draw[->, thick] (Su) -- (Suu);
    \draw[->, thick] (Su) -- (Sud);
    \draw[->, thick] (Sd) -- (Sud);
    \draw[->, thick] (Sd) -- (Sdd);
    
    % Timeline
    \draw[->, thick] (0,-4.5) -- (6,-4.5);  % Moved timeline down slightly too
    \node at (0,-4.5) [below] {$t=0$};
    \node at (3,-4.5) [below] {$t=T/2$};
    \node at (6,-4.5) [below] {$t=T$};
    
    \end{tikzpicture}
        \caption{Two-period binomial lattice. Stock prices evolve forward through time, creating an expanding set of possible outcomes. Option payoffs are calculated at the terminal nodes, after which option values at interior nodes can be calculated using \cref{eq:risk-neutral-expectancy}. The symbols $C_{i,j}$ represent the algorithmic notation for the option values, where $i$ is the time point and $j$ is the number of up-ticks the stock price has moved. }
    \label{fig:crr-twoperiod}
\end{figure}

A detail not yet discussed is the choice of the factors $u$ and $d$. The authors of the original paper have defined $u = e^{\sigma\sqrt{T/n}}$ and $d = e^{-\sigma\sqrt{T/n}}$, where $\sigma$ is the annualized volatility (e.g. estimated from historical data) of the log-return of the asset, $T$ is the total time in years, and $n$ is the number of time periods. This is useful for several reasons: firstly, it allows for the model to converge to the famous Black-Scholes-Merton (BSM) model as $n \rightarrow \infty$. Secondly, the lattice recombines for all permutations of a price path. This ensures computational feasibility as the number of states grows linearly instead of exponentially. Another detail to note is that the discount rate used in the period calculations must be adjusted such that it yields the same return as the initial risk-free rate used in the one-period example. A continuous compounding rate $e^{rT/n}$ is often used in lieu of the discrete version. \cite{cox1979option} \cite{hull2013fundamentals}

The implementation of the CRR model comprises three steps: first, compute the price of the underlying at all the terminal nodes. Then, calculate the corresponding option payoffs for the terminal nodes. Finally, backtrack the lattice to compute the option values at nodes in the previous period, working towards the initial node. The following pseudocode is based on the Python implementation by Jonathon Emerick \cite{thequantpy2024github}. Let $S_0$ be the initial stock price and $n$ the number of periods. The nodes of the recombining lattice can be expressed in terms of indices $i$ and $j$, where $0 \leq i \leq n$ are points in time, ranging from the start to maturity, and $0 \le j \le i$ are the nodes at time point $i$ based on the number of up-ticks $j$ the stock price has moved. In other words, the stock price at each node is defined as $S_{i,j} = S_0u^jd^{i-j}$. In the same manner, $C_{i,j}$ represents the option price at the corresponding node. The option price  $C_{0,0}$ is calculated according to \cref{alg:crr-european}.

\begin{algorithm}
\caption{CRR European Option Pricing}
\label{alg:crr-european}
\textbf{Data:} $S_0$ (initial stock price), $K$ (strike price), $T$ (time to maturity), $r$ (risk-free rate), $n$ (periods), $\sigma$ (volatility), type $\in \{\text{CALL}, \text{PUT}\}$\\
\textbf{Result:} Option price at $t=0$\\
$\Delta t \gets T/n$\;
$u \gets e^{\sigma\sqrt{\Delta t}}$\;
$d \gets 1/u$\;
$disc \gets e^{-r\Delta t}$\;
$p \gets (e^{r\Delta t} - d)/(u - d)$\;
/* Compute stock prices at terminal nodes */\\
Initialize $S[0..n]$\;
$S[0] \gets S_0 \cdot d^n$\;
\For{$j \gets 1$ \KwTo $n$}{
    $S[j] \gets S[j-1] \cdot u/d$\;
}
/* Compute option payoffs at terminal nodes */\\
Initialize $C[0..n]$\;
\For{$j \gets 0$ \KwTo $n$}{
    \If{type = CALL}{
        $C[j] \gets \max(0, S[j] - K)$\;
    }
    \Else{
        $C[j] \gets \max(0, K - S[j])$\;
    }
}
/* Backward induction through the lattice */\\
\For{$i \gets n-1$ \KwSty{to} $0$}{
    \For{$j \gets 0$ \KwTo $i$}{
        $C[j] \gets disc \cdot (p \cdot C[j+1] + (1-p) \cdot C[j])$\;
    }
}

\Return{$C[0]$}\;
\end{algorithm}

A key advantage of the CRR and other lattice-based models is their natural ability to price American options, which generally cannot be valued using closed-form solutions like the BSM model \cite{wilmott2013paul}. For European options, the backward induction step in ~\cref{alg:crr-european} calculates the option value as
\begin{equation*}
C[j] \gets disc \cdot (p \cdot C[j+1] + (1-p) \cdot C[j]).
\end{equation*}

For American options, this calculation is modified to include the early exercise possibility. Hence, the option value becomes the maximum of immediate exercise versus holding:
\begin{equation*}
C[j] \gets \max(\text{Exercise Value}, disc \cdot (p \cdot C[j+1] + (1-p) \cdot C[j])),
\end{equation*}

where Exercise Value equals $\max(K - S[j], 0)$ for put options or $\max(S[j] - K, 0)$ for call options, representing the payoff from immediate exercise at that node.

\subsection{Naive GPU-acceleration}
The sequential algorithm has an asymptotic time complexity of $O(n^2)$ due to the nested loop in step 3. Clearly, processing each node at every time step becomes intensive as $n$ grows large. There is a clear dependency chain between the nodes of subsequent time steps, as every node is computed using its children. There are, however, no dependencies among nodes within the same time step, and these could at least in theory be computed in parallel. We thus seem to have rather sizable potential speedups for large values of $n$. Kolb and Pharr \cite{pharr2005gpu} implement a GPU-accelerated version of this nature. Similarly to the sequential version, the terminal stock and option values are calculated first, after which the tree backtracking ensues. For each time step, an amount of threads equal to the amount of nodes are spawned, letting each thread compute a single node from its child nodes in the previous iteration. Threads are synchronized in each time step, ensuring no data races occur when moving down the dependency chain. Intermediate results are stored in two alternating arrays from which to read and write data. For maximum GPU utilization the algorithm is run in parallel for ``a thousand or so independent options''. The full source code (written in Cg as this was in 2005, before even the existence of CUDA) \textbf{(consider making this a footnote!)} can be found in the original article \cite{pharr2005gpu}. Given enough parallelization, the practical time complexity for a fixed n can thus be reduced to $O(n)$ \textbf{(should I use this terminology when it's not asymptotic?)}. The authors used $n=1024$ and have plotted the achieved throughput (options/s) as a function of the total amount of American options. The sequential CPU version achieves a constant throughput of around 110 \textbf{(?see graph)} options/s. The GPU-accelerated version performs worse at roughly $n < 5$, likely due to the overhead associated with GPU code, but increasingly outperforms the CPU version above this threshold. This throughput then tapers off to a a constant around 1150 options/s, yielding a 10x speedup. The limit can be attributed to maximum utilization of all parallel computing capability, or hitting another bottleneck before reaching this point (e.g. in memory bandwidth). Factors like the latter also likely explain the general S-shape curve, as opposed to a linear function \textbf{(these are my own conclusions, is this ok?)}.

At large values of $n$, there is a real possibility of the naive parallelization above running into synchronization overhead bottlenecks between threads. Since each thread reads two child nodes to calculate the current node, the algorithm requires the threads to communicate at every time step. Furthermore, this communication overhead is exacerbated once the lattice is so big it has to be split up over multiple blocks, as inter-block communication is restricted to using the much slower global memory (REWRITE THIS BETTER AFTER FINISHING THE GPU CHAPTER). At some point it is more efficient to sacrifice parallelism for less communication overhead, which can be done by letting a thread compute more nodes over several time steps. While this means more sequential computation, it also avoids having to communicate intermediate values between threads at every time step. A naive approach would be to assign multiple nodes across several periods to each thread. This, however, introduces a substantial amount of redundant calculations, as nodes must be computed multiple times by several threads. More sophisticated approaches have been proposed, such as the ``triangle method'' by Suo et.\ al.\ \cite{suo2015gpu}

\subsection{Additional Parallelization Across Time}
Ganesan, Chamberlain and Buhler \cite{ganesan2009acceleration} present another approach that aims to utilize parallelism over the time periods in addition to within them. This method focuses more on pricing a single option, and achieves parallelism over different periods by a clever reformulation of the problem that breaks the direct dependencies between the first and last set of nodes. \cref{eq:risk-neutral-expectancy} relates the (European) option values at time $i$ to the prices at the next time point $i+1$. By repeatedly substituting the same formula into itself and expanding, one obtains a general formula that relates the option values at the nodes at a previous time $i-m$ with the current time $i$:

\begin{equation}
    F_{i-m}(j) = e^{-m r \Delta t} \sum_{k=0}^m c_k F_i(j+k)
\label{relative-prices}
\end{equation}

where $0 \leq j \leq i-m$ are the nodes at time $i-m$, and the coefficients $c_k, 0 \leq k \leq m$ are the corresponding (risk-neutral) probabilities of the different possible price paths from node $j$ at time $i-m$ to the nodes $j+k$ at time $i$. Just like the one-period version computes the current value using a weighted sum (risk-neutral expected value) of the values in the future two states, this general formula extends the weighted sum to include all the nodes over several future periods that affect its value. The coefficients in this formula follow the same pattern as the option values themselves, and can be computed through backward induction. Starting from time $t$ itself, where each coefficient represents the direct relationship of a node with itself, these coefficients are built up as we move backward in time. With each step backward, they are updated using the risk-neutral probabilities to reflect all possible paths between the two time points.

The key insight is that while the coefficients in this reformulation still exhibits the same sequential dependency chains between sequential time points, they can be computed independently for different segments of the lattice. Unlike for the actual option values, there is no strict requirement for starting at the terminal nodes when calculating relative option values. Using this, the authors present the following outline of a parallel algorithm:

PSEUDO ALGORITHM

1. Divide the lattice of N time steps into p partitions, each of length N/p
2. For all partitions except the rightmost one, calculate coefficients that relate the option values at the left boundary to those at the right boundary. This is done recursively and in parallel, backtracking from the right edge to the left. Since the rightmost partition already has the option values available at its right edge (terminal nodes) we can simply compute the option prices normally here.
3. Once all partition coefficients have been calculated, use equation \eqref{relative-prices} to sequentially calculate the option value at each partition boundary, rapidly propagating towards the initial node while "skipping" many intermediate calculations.

Figure ABC depicts the algorithm.


\begin{figure}[h]
    \centering
    \includegraphics[height=5cm]{CRRpartitioned.png}
    \caption{A visualization of the parallelized CRR algorithm using partitioning. BLA BLA BLA lorem ipsum. MAKE YOUR OWN PICTURE OF THIS, OR CHECK IF THE FIGURES ARE OK TO USE UNDER COPYRIGHT}
    \label{fig:combined}
\end{figure}


\footnote{For what it's worth, the authors state that this can also be applied to American options by "filling in the intermediary nodes". I have been thinking about this for long now, and this still does not make sense to me. I am skeptical to claim that this is doable without having seen a better explanation on the matter. Hence, my performance analysis ignores the contribution of this step.}

Again, asymptotically, we still have $O(n^2)$ as we do computations for every node in the tree. The coefficient calculations is directly comparable to the actual option value calculations from the previous version, but we expect a factor $p$ speedup due to performing this work in parallel over all partitions. We then have to calculate the actual option values at all the nodes at the partition boundaries using \eqref{relative-prices}. The sum contains an amount of terms equal to the partition width plus one, $n/p+1$. Given enough parallel computing resources to calculate this sum for all the nodes simultaneously, this is in total an $O(n)$ operation. In practice, however, the dependency chain of the work has been reduced enough to reduce overall execution time, and the authors report a 2x speedup over a general parallel algorithm. Furthermore, they derive the optimal number of partitions $p$ for minimal execution time, and find it to be directly proportional to the square root of the amount of time steps, but inversely proportional to the square root of the latency of propagation between the partitions. Dividing the lattice into more partitions improves execution time due to parallelism up to a certain point, where the communication and boundary calculation overhead between the partitions exceed the former speedups. The paper compares this tradeoff by plotting execution time of an n=1000 size problem as a function of the number of partitions for different communication latencies (do I mention this, add it in the thesis or what?)\footnote{The original paper simplifies the analysis by only considering the communication overhead between partitions as opposed to also including the option value calculations at the boundaries. The conclusions, however, remain the same, as the choice of $p$ does not affect the computational cost of calculating the option values at the boundaries. More partitions means more boundaries to calculate in, but the smaller partition width means less summation terms. (Do I need some appendix deriving this stuff? This is my analysis based on the paper.)}.


\section{GPU Acceleration of Monte Carlo Methods} \label{sec:gpu-mc}
\subsection{Monte Carlo Methods}
Monte Carlo (MC) methods are a class of computational algorithms that approximate solutions to problems through random sampling. Unlike analytical and deterministic numerical methods that rely heavily on domain-specific mathematical theory, MC methods are relatively simple and model-agnostic. They depend primarily on the \emph{law of large numbers}, which states that the sample average tends toward the true expected value with increasing sample size \cite{Ross2020prob}. Therefore, with a well-chosen sampling distribution whose expectation matches the target quantity, the average of a large number of simulated outcomes provides a reliable approximation of the solution. While true random number generation is difficult, there exist many so-called pseudorandom number generation algorithms, whose deterministic sequences are statistically indistinguishable from true randomness. To achieve sampling from a specific probability distribution, the general approach is to first use a \emph{linear congruential generator} that samples numbers from a uniform distribution $U(0,1)$, and then apply a transformation to map these to the desired distribution. A common example is the Box-Muller transform for a standard normal mapping $U(0,1) \rightarrow N(0,1)$. \cite{gentle2003random}

Many software libraries contain easy-to-use random number generators from various distributions. This, coupled with the availability of affordable computing power, has made MC methods hugely popular for brute force problem solving across different domains. Their generality, however, still comes at a significant computational cost. While analytical and other numerical methods exploit problem-specific structure for a faster convergence, MC methods typically require a large number of iterations to produce accurate results. Consequently, MC methods are often employed for high-dimensional problems where traditional approaches fail or become exceedingly slow \cite{gentle2003random}. In derivatives pricing, MC methods are mostly used for exotic options with complex payoff structures, e.g. multi-asset options whose payoff depend on numerous underlying assets \cite{hull2016options,wilmott2013paul}.

Option pricing by MC simulation relies on the same risk-neutral valuation framework presented earlier in \cref{sec:risk-neutral-theory}. While the BSM model provides an analytical solution to a partial differential equation for the expected discounted payoff, the MC approach instead estimates this value numerically by computing the discounted average of many simulated option payoffs, each obtained from a risk-neutral stock price path \cite{boyle1977options}. The result is always an approximation, but converges toward the theoretical value as the number of simulated paths increases. The construction and dynamic maintenance of a replicating portfolio naturally extends to continuous-time models. The stock price dynamics used for MC simulations are often a discretized version of the \emph{geometric Brownian motion} process used in the continuous BSM model, which is also the behavior of the CRR model in the limit as $n \rightarrow \infty$. Under these assumptions, one can solve for the exact distribution of the stock price at a future time point $t$, and thus the discretization does not introduce an error. At each point in time, the stock price is updated according to
\begin{equation*}
S_{t+\Delta t} = S_t \cdot \exp \left( \nu \Delta t + \sigma \sqrt{\Delta t} \cdot \epsilon_i \right),
\label{eq:GBM-price}
\end{equation*}
where $\nu=r-\frac{1}{2}\sigma^2$ and $\epsilon_i \sim N(0,1)$. Hence, there is no need to use more than one time period unless the payoff function is path dependent, as for e.g. Asian options whose payoff is calculated using the average stock price over the holding period. In this case, much like the CRR algorithm, we get a better approximation with larger values of $n$ and smaller time steps. \cref{alg:MC-algo}, based on the implementation by Clelow and Strickland, demonstrates a generic MC implementation \cite{clelow1998implementing}. The algorithm has an asymptotic time complexity of $O(M \cdot n)$ as we run $M$ simulations, each $n$ periods long, and calculate the option payoff in each one. The payoff calculation complexity ranges from $O(1)$ for simpler options to $O(n)$ for more complex, path dependent options. 

\begin{algorithm}
\caption{MC Option Pricing}
\label{alg:MC-algo}
\textbf{Data:} $S_0$ (initial stock price), $K$ (strike price), $T$ (time to maturity), $r$ (risk-free rate), $n$ (time steps), $\sigma$ (volatility), $M$ (simulated paths), $\text{payoff}(\cdot)$ (payoff function)\\
\textbf{Result:} Option price at $t=0$\\

$\Delta t \gets T/n$\;
$\nu \gets r - 0.5 \cdot \sigma^2$\;
$\text{nudt} \gets \nu \cdot \Delta t$\;
$\text{sigsqrt} \gets \sigma \cdot \sqrt{\Delta t}$\;

Initialize $C_{\text{sum}} \gets 0$\;

/* Simulate $M$ stock price paths */\\
\For{$j \gets 1$ \KwTo $M$}{
    Initialize $S[0] \gets S_0$\;
    /* Simulate stock price path through $n$ time steps */\\
    \For{$i \gets 1$ \KwTo $n$}{
        Sample $\epsilon \sim \mathcal{N}(0,1)$\;
        $\ln S[i] \gets \ln S[i-1] + \text{nudt} + \text{sigsqrt} \cdot \epsilon$\;
        $S[i] \gets \exp(\ln S[i])$\;
    }
    /* Compute option payoff for the simulated path */\\
    $C_j \gets \text{payoff}(S[0..n])$\;
    $C_{\text{sum}} \gets C_{\text{sum}} + C_j$\;
}

/* Discount and average the payoffs */\\
$C_0 \gets \exp(-r \cdot T) \cdot \frac{C_{\text{sum}}}{M}$\;

\Return{$C_0$}\;
\end{algorithm}


\subsection{Naive GPU-acceleration}
MC simulation is considered an \emph{embarrassingly parallel} problem, since an accelerated version can be obtained by simply running the simulations in parallel without any further algorithm redesign. Instead, the difficulty shifts to maintaining the quality and independence of the random number streams generated in parallel. Because only a finite set of states can be represented in binary, a deterministic sequence (such as one produced by a pseudorandom number generator) must eventually repeat. Moreover, problems can arise even before this point if significant correlations exist between number streams. Therefore, a parallel MC implementation must partition the state space carefully to avoid these issues while still ensuring efficiency \cite{gentle2003random}. This necessitates the use of generators specifically designed for parallel architectures, where each thread can produce an independent and high-quality random stream without introducing statistical bias. Early GPU implementations, such as those by Howes and Thomas \cite{nguyen2007gpu}, had to manually construct such generators. Today, GPU libraries like cuRAND provide various parallel random number generators as standard functionality, eliminating the need for manual implementation.

Given the resources to run $m$ simulations in parallel, the time complexity could thus be reduced to $O(\frac{M}{m}\cdot n)$. The aforementioned authors \cite{nguyen2007gpu} compared the performance of both normal random number generation and MC pricing of exotic Asian and lookback options, using an Nvidia GeForce 8 GPU and AMD Quad Opteron 2.2 GHz CPU. A 26x speedup was achieved in pure random number generation, while a 59x and 23x speedup improvement were seen for MC pricing of Asian and lookback options respectively. These results show that even fairly naive GPU implementations of the early days (2007) achieved substantial speedups over multi-core CPU versions for MC option pricing, despite the inherent challenges of parallel random number generation. When examining the performance of the simulation computations in isolation (using constant values as opposed to random numbers), the theoretical speedups reached 118x for Asian options and 45x for lookback options. This indicates that RNG becomes a proportionally larger bottleneck on GPUs compared to CPUs. The choice of random number generator also depends on the option type and memory constraints, as some option payoffs require storing intermediate values in memory. In this example, the sum used for the average calculation in the Asian option can be accumulated in a single variable, leading to minimal memory requirements. This enabled the use of the faster Wallace RNG, which could not be used in the pricing of more memory-intensive lookback options that needed to store entire price paths.

\subsection{Further Hardware Optimization}
Unlike the CRR model, where algorithmic reformulation was necessary to expose hidden parallelism, Monte Carlo simulation presents a fundamentally different optimization challenge. The parallelism is already fully exposed at the algorithmic level -- each simulation path is completely independent, requiring no communication or synchronization with other paths. This embarrassingly parallel structure means that further speedups must come not from mathematical reformulation, but from efficiently mapping this abundant parallelism onto GPU hardware constraints. While techniques such as variance reduction methods and the use of quasi-random numbers can improve convergence rates \cite{clelow1998implementing}, they benefit any implementation equally and are thus not relevant to the scope of this thesis. Instead, further GPU acceleration requires addressing hardware-specific challenges, such as efficient random number generation, optimizing memory access patterns, and resource utilization. 

Liu et al. demonstrate several optimization strategies for further speeding up parallel MC option pricing. The identified problems were mostly forms of inefficient memory access patterns and use of resources. The simplest optimization was to compress the working set -— that is, the amount of memory each thread must keep track of during simulation -- reducing reliance on slow global memory. The extent to which this is achievable heavily depends on the option type and choice of RNG \textbf{(if this sentence is MY thoughts, how do I separate it from citation?)}. Another common bottleneck is the memory bandwidth, for which reorganizing for coalesced accesses serves as a solution. The fixed amount of registers per streaming multiprocessor (SM) can also lead to sub-optimal parallelism if the implementation requires a high amount of registers in use per thread, leading to "leaving parallelism on the table". A proposed solution is to split the process into smaller GPU kernels, each responsible for sub-tasks (e.g. one for RNG, another for simulation). While this enables more efficient processor utilization, it comes at a cost of more global memory accesses between kernels. These techniques enabled a 43x speedup for exotic MC option pricing on an Nvidia Tesla C1060 GPU compared to an Intel 8-core Xeon 2.0 GHz CPU. \cite{liu2010efficient}

The paper also explores the practical case of large workloads where the threads compute multiple price paths, and the tradeoff between two such execution strategies. In ``path mode'' a thread computes its paths sequentially from start to finish. This minimizes memory usage and is well suited for homogeneous workloads like the paths for the same option. In contrast, ``slice mode'' divides the computations across time steps, and computes the corresponding simulation step for all paths. This is naturally more memory intensive as intermediary data is required for all the paths. On the other hand, slice mode handles heterogeneous workloads better, e.g. the case of distributing calculations for multiple options over the threads. If these options have different maturities, some path simulations will finish earlier than others, leading to control-flow \emph{warp divergence}\textbf{(mention this in GPU chapter first time, and no need to emph it here)}. Slice mode alleviates this by structuring the computations to minimize the cost of such divergence. \cref{fig:combined} depicts the different execution modes and their effect on divergence. While these techniques were introduced in 2010 and GPU architectures have evolved significantly since then (e.g., with better warp scheduling and memory handling), the underlying tradeoffs between memory usage, synchronization, and parallel efficiency remain central to high-performance Monte Carlo implementations, even on modern GPUs. \cite{liu2010efficient}

\begin{figure}[htbp]
\centering
\begin{tikzpicture}[
    node distance=0.7cm,
    every node/.style={minimum size=0.6cm, font=\footnotesize, thick, draw=black!70}
]

% Path Mode Title
\node[draw=none, font=\bfseries] at (5, 6.5) {Path Mode};

% PATH MODE
% Thread 1 (Blue) - Path 1
\node[rectangle, fill=blue!90, text=white] (b11) at (0, 5) {1.1};
\node[circle, fill=blue!90, text=white, right=of b11] (b12) {1.2};
\node[circle, fill=blue!90, text=white, right=of b12] (b13) {1.3};

% Thread 2 (Red) - Path 1  
\node[rectangle, fill=red!80, text=white] (g11) at (0, 4) {1.1};
\node[circle, fill=red!80, text=white, right=of g11] (g12) {1.2};
\node[circle, fill=red!80, text=white, right=of g12] (g13) {1.3};
\node[circle, fill=red!80, text=white, right=of g13] (g14) {1.4};
\node[circle, fill=red!80, text=white, right=of g14] (g15) {1.5};

% Dotted line and DIVERGENCE text after path 1
\draw[dotted, line width=1.5pt] (b13.east) -- ++(1.5,0);
\node[draw=none, font=\scriptsize] at (4.8, 5) {DIVERGENCE};



% Thread 1 (Blue) - Path 2 (lighter)
\node[rectangle, fill=blue!40, text=white] (b21) at (6, 5) {2.1};
\node[circle, fill=blue!40, text=white, right=of b21] (b22) {2.2};
\node[circle, fill=blue!40, text=white, right=of b22] (b23) {2.3};

% Thread 2 (Red) - Path 2 (lighter)
\node[rectangle, fill=red!40, text=white] (g21) at (6, 4) {2.1};
\node[circle, fill=red!40, text=white, right=of g21] (g22) {2.2};
\node[circle, fill=red!40, text=white, right=of g22] (g23) {2.3};
\node[circle, fill=red!40, text=white, right=of g23] (g24) {2.4};
\node[circle, fill=red!40, text=white, right=of g24] (g25) {2.5};

% Dotted line and DIVERGENCE text after path 2
\draw[dotted, line width=1.5pt] (b23.east) -- ++(1.5,0);
\node[draw=none, font=\scriptsize] at (10.3, 5) {DIVERGENCE};

% Arrows
\foreach \i/\j in {b11/b12, b12/b13, g11/g12, g12/g13, g13/g14, g14/g15,
                   b21/b22, b22/b23, g21/g22, g22/g23, g23/g24, g24/g25}
    \draw[->, thick] (\i) -- (\j);

% SLICE MODE
\node[draw=none, font=\bfseries] at (5, 2) {Slice Mode};

% Thread 1 (Blue) - alternating colors
\node[rectangle, fill=blue!90, text=white] (sb11) at (0, 0.5) {1.1};
\node[circle, fill=blue!40, text=white, right=of sb11] (sb21) {2.1};
\node[circle, fill=blue!90, text=white, right=of sb21] (sb12) {1.2};
\node[circle, fill=blue!40, text=white, right=of sb12] (sb22) {2.2};
\node[circle, fill=blue!90, text=white, right=of sb22] (sb13) {1.3};
\node[circle, fill=blue!40, text=white, right=of sb13] (sb23) {2.3};

% Thread 2 (Red) - alternating colors
\node[rectangle, fill=red!80, text=white] (sg11) at (0, -0.5) {1.1};
\node[circle, fill=red!40, text=white, right=of sg11] (sg21) {2.1};
\node[circle, fill=red!80, text=white, right=of sg21] (sg12) {1.2};
\node[circle, fill=red!40, text=white, right=of sg12] (sg22) {2.2};
\node[circle, fill=red!80, text=white, right=of sg22] (sg13) {1.3};
\node[circle, fill=red!40, text=white, right=of sg13] (sg23) {2.3};
\node[circle, fill=red!80, text=white, right=of sg23] (sg14) {1.4};
\node[circle, fill=red!40, text=white, right=of sg14] (sg24) {2.4};
\node[circle, fill=red!80, text=white, right=of sg24] (sg15) {1.5};
\node[circle, fill=red!40, text=white, right=of sg15] (sg25) {2.5};

% Arrows
\foreach \i/\j in {sb11/sb21, sb21/sb12, sb12/sb22, sb22/sb13, sb13/sb23,
                   sg11/sg21, sg21/sg12, sg12/sg22, sg22/sg13, sg13/sg23,
                   sg23/sg14, sg14/sg24, sg24/sg15, sg15/sg25}
    \draw[->, thick] (\i) -- (\j);

% Single divergence - dotted horizontal line
\draw[dotted, line width=1.5pt] (sb23.east) -- ++(4.5,0);
\node[draw=none, font=\scriptsize] at (8, 0.5) {DIVERGENCE};

\end{tikzpicture}
\caption{GPU warp divergence in path mode versus slice mode execution. In path mode (top), threads complete entire paths sequentially, causing divergence at each path boundary when threads have different numbers of steps. In slice mode (bottom), threads process steps in parallel across paths, resulting in only a single divergence point when shorter options complete. Blue represents thread 1 (3 steps), red represents thread 2 (5 steps), with darker shades for path 1 and lighter shades for path 2.}
\label{fig:gpu-divergence}
\end{figure}





\clearpage


%% Huomaa seuraavassa kappaleessa lainausmerkkien ulkopuolella piste, 
%% koska piste ei lopeta lainattua tekstinp\"atk\"a\"a.
%% Jos lainattu tekstinp\"atk\"a loppuu v\"alimerkkiin, tulee v\"alimerkki
%% lainausmerkkien sis\"alle: 
%% "Et tu, Brute?" sanoi Caesar kuollessaan.
Tutkimustuloksien merkityst\"a on aina syyt\"a arvioida ja tarkastella
kriittisesti.  Joskus tarkastelu voi olla t\"ass\"a osassa, mutta se
voidaan my\"os j\"att\"a\"a viimeiseen osaan, jolloin viimeisen osan nimeksi
tulee >>Tarkastelu>>. Tutkimustulosten merkityst\"a voi arvioida my\"os
>>Johtop\"a\"at\"okset>>-otsikon alla viimeisess\"a osassa. 

T\"ass\"a osassa on syyt\"a my\"os arvioida tutkimustulosten luotettavuutta.
Jos tutkimustulosten merkityst\"a arvioidaan >>Tarkastelu>>-osassa,
voi luotettavuuden arviointi olla my\"os siell\"a. 

\clearpage

\section{Summary}  \label{sec:summary}

\section{Conclusions}  \label{sec:conclusions}


Opinn\"aytteen tekij\"a vastaa siit\"a, ett\"a opinn\"ayte on t\"ass\"a dokumentissa
ja opinn\"aytteen tekemist\"a k\"asittelevill\"a luennoilla sek\"a
harjoituksissa annettujen ohjeiden mukainen muotoseikoiltaan,
rakenteeltaan ja ulkoasultaan.\cite{grochowski2004best}


\cleardoublepage

% Start of Appendices
\appendix
\section{Derivation of Risk-Neutral Probability Form}  % For 
\label{appendix:risk_neutral_derivation}

In this appendix, we derive the risk-neutral probability form of the one-period binomial model option pricing formula.

\begin{align}
&\text{Starting from \eqref{eq:replicating-portfolio}:} \nonumber\\[0.7em]
&\frac{f_u - f_d}{S_0(u-d)}S_0 + \frac{f_d \cdot u-f_u \cdot d}{(u-d)(1+r)} \nonumber\\[0.7em]
&=\frac{f_u - f_d}{u-d} + \frac{f_d \cdot u-f_u \cdot d}{(u-d)(1+r)} \nonumber\\[0.7em]
&=\frac{(f_u - f_d)(1+r)}{(u-d)(1+r)} + \frac{f_d \cdot u - f_u \cdot d}{(u-d)(1+r)} \nonumber\\[0.7em]
&=\frac{f_u(1+r) - f_d(1+r) + f_d \cdot u - f_u \cdot d}{(u-d)(1+r)} \nonumber\\[0.7em]
&= \frac{f_u[(1+r) - d] + f_d[u - (1+r)]}{(u-d)(1+r)} \nonumber\\[0.7em]
&= \frac{1}{1+r} \cdot \frac{f_u[(1+r) - d] + f_d[u - (1+r)]}{u-d} \nonumber\\[0.7em]
&= \frac{1}{1+r} \left( f_u \cdot \frac{(1+r) - d}{u-d} + f_d \cdot \frac{u - (1+r)}{u-d} \right)\nonumber
\end{align}

This final form reveals the risk-neutral probabilities: $\tilde p = \frac{(1+r) - d}{u-d}$ and $\tilde q = 1-\tilde p = \frac{u - (1+r)}{u-d}$.

The no-arbitrage condition ensures $\tilde p$ and $\tilde q$ are correctly bounded by 0 and 1. If $1+r > u$, investors could profit by shorting the stock and investing in the risk-free asset. Conversely, if $d > 1+r$, they could earn guaranteed profits. Therefore, $d \leq 1+r \leq u$ must hold, which leads to $0\leq \tilde p, \tilde q \leq 1$. Furthermore, $\tilde p + \tilde q = 1$. Thus, our risk-neutral probabilities form a valid probability distribution over the two possible outcomes.



\phantomsection

\addcontentsline{toc}{chapter}{\bibname}
\bibliographystyle{IEEEtran}
\bibliography{bibliography.bib}


\end{document}